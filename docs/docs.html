<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_c0yxfgf3c3ml-1.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-1 0}.lst-kix_a2tayeel68j9-7>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-1>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-1}.lst-kix_c0yxfgf3c3ml-7>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-7}.lst-kix_c0yxfgf3c3ml-6>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-6,decimal) ". "}.lst-kix_a2tayeel68j9-8>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-5>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-5,lower-roman) ". "}.lst-kix_a2tayeel68j9-3>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-4>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-4,lower-latin) ". "}ol.lst-kix_c0yxfgf3c3ml-4.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-4 0}.lst-kix_a2tayeel68j9-2>li:before{content:"-  "}.lst-kix_a2tayeel68j9-6>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-3>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-3,decimal) ". "}.lst-kix_c0yxfgf3c3ml-0>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-0,decimal) ". "}.lst-kix_a2tayeel68j9-5>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-2>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-2,lower-roman) ". "}.lst-kix_a2tayeel68j9-4>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-1>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-1,lower-latin) ". "}.lst-kix_c0yxfgf3c3ml-0>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-0}ol.lst-kix_c0yxfgf3c3ml-7.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-7 0}ol.lst-kix_c0yxfgf3c3ml-0{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-1{list-style-type:none}.lst-kix_c0yxfgf3c3ml-5>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-5}.lst-kix_c0yxfgf3c3ml-2>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-2}ol.lst-kix_c0yxfgf3c3ml-4{list-style-type:none}ul.lst-kix_ymjab77f7l4-0{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-5{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-2{list-style-type:none}.lst-kix_c0yxfgf3c3ml-7>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-7,lower-latin) ". "}ol.lst-kix_c0yxfgf3c3ml-3{list-style-type:none}ul.lst-kix_ymjab77f7l4-3{list-style-type:none}.lst-kix_c0yxfgf3c3ml-8>li:before{content:"" counter(lst-ctn-kix_c0yxfgf3c3ml-8,lower-roman) ". "}ol.lst-kix_c0yxfgf3c3ml-8{list-style-type:none}ul.lst-kix_ymjab77f7l4-4{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-0.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-0 0}ul.lst-kix_ymjab77f7l4-1{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-6{list-style-type:none}ul.lst-kix_ymjab77f7l4-2{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-3.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-3 0}ol.lst-kix_c0yxfgf3c3ml-7{list-style-type:none}ul.lst-kix_ymjab77f7l4-7{list-style-type:none}ul.lst-kix_ymjab77f7l4-8{list-style-type:none}ul.lst-kix_ymjab77f7l4-5{list-style-type:none}ul.lst-kix_ymjab77f7l4-6{list-style-type:none}.lst-kix_c0yxfgf3c3ml-8>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-8}ul.lst-kix_jgz42nz4w22j-8{list-style-type:none}ul.lst-kix_jgz42nz4w22j-7{list-style-type:none}ul.lst-kix_jgz42nz4w22j-6{list-style-type:none}.lst-kix_ymjab77f7l4-5>li:before{content:"-  "}.lst-kix_ymjab77f7l4-7>li:before{content:"-  "}ul.lst-kix_jgz42nz4w22j-5{list-style-type:none}.lst-kix_jgz42nz4w22j-6>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-8>li:before{content:"-  "}ul.lst-kix_jgz42nz4w22j-4{list-style-type:none}ul.lst-kix_jgz42nz4w22j-3{list-style-type:none}ul.lst-kix_jgz42nz4w22j-2{list-style-type:none}.lst-kix_ymjab77f7l4-4>li:before{content:"-  "}.lst-kix_ymjab77f7l4-8>li:before{content:"-  "}ul.lst-kix_jgz42nz4w22j-1{list-style-type:none}.lst-kix_jgz42nz4w22j-5>li:before{content:"-  "}.lst-kix_c0yxfgf3c3ml-4>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-4}ol.lst-kix_c0yxfgf3c3ml-6.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-6 0}.lst-kix_ymjab77f7l4-1>li:before{content:"-  "}.lst-kix_ymjab77f7l4-3>li:before{content:"-  "}.lst-kix_ymjab77f7l4-2>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-7>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-0>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-1>li:before{content:"-  "}.lst-kix_ymjab77f7l4-0>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-2>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-4>li:before{content:"-  "}.lst-kix_jgz42nz4w22j-3>li:before{content:"-  "}ul.lst-kix_a2tayeel68j9-0{list-style-type:none}ul.lst-kix_a2tayeel68j9-2{list-style-type:none}.lst-kix_c0yxfgf3c3ml-3>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-3}ul.lst-kix_a2tayeel68j9-1{list-style-type:none}ol.lst-kix_c0yxfgf3c3ml-2.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-2 0}ul.lst-kix_a2tayeel68j9-4{list-style-type:none}ul.lst-kix_a2tayeel68j9-3{list-style-type:none}ul.lst-kix_a2tayeel68j9-6{list-style-type:none}ul.lst-kix_a2tayeel68j9-5{list-style-type:none}.lst-kix_c0yxfgf3c3ml-6>li{counter-increment:lst-ctn-kix_c0yxfgf3c3ml-6}ul.lst-kix_a2tayeel68j9-8{list-style-type:none}ul.lst-kix_a2tayeel68j9-7{list-style-type:none}.lst-kix_a2tayeel68j9-1>li:before{content:"-  "}.lst-kix_a2tayeel68j9-0>li:before{content:"-  "}ol.lst-kix_c0yxfgf3c3ml-5.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-5 0}ul.lst-kix_jgz42nz4w22j-0{list-style-type:none}.lst-kix_ymjab77f7l4-6>li:before{content:"-  "}ol.lst-kix_c0yxfgf3c3ml-8.start{counter-reset:lst-ctn-kix_c0yxfgf3c3ml-8 0}ol{margin:0;padding:0}table td,table th{padding:0}.c12{background-color:#ffffff;margin-left:36pt;padding-top:3pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c10{background-color:#ffffff;color:#222222;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c11{color:#24292e;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:25pt;font-family:"Arial";font-style:normal}.c13{color:#24292e;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c4{color:#24292e;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c27{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c25{padding-top:0pt;padding-bottom:0pt;line-height:1.45;orphans:2;widows:2;text-align:left}.c24{padding-top:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c19{color:#000000;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c20{text-decoration:none;vertical-align:baseline;font-size:19pt;font-family:"Arial";font-style:normal}.c6{font-size:10pt;font-family:"Courier New";color:#d73a49;font-weight:400}.c32{font-size:10pt;font-family:"Courier New";color:#032f62;font-weight:400}.c5{font-size:10pt;font-family:"Courier New";color:#6a737d;font-weight:400}.c8{font-size:10pt;font-family:"Courier New";color:#24292e;font-weight:400}.c7{font-size:10pt;font-family:"Courier New";color:#6f42c1;font-weight:400}.c29{font-size:10pt;font-family:"Courier New";color:#005cc5;font-weight:400}.c30{font-size:8pt;font-family:"Courier New";font-weight:400}.c28{margin-left:36pt;padding-left:0pt}.c36{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c0{padding:0;margin:0}.c33{color:#000000}.c23{background-color:#ffffff}.c22{font-size:22pt}.c17{color:#24292e}.c18{font-weight:700}.c26{font-size:20pt}.c15{font-size:12pt}.c31{font-size:13pt}.c35{font-size:10pt}.c21{font-size:18pt}.c34{font-size:25pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body><div class="c23 c36"><p class="c2"><span class="c3">AIParrot </span></p><p class="c1"><span class="c3"></span></p><p class="c2"><span class="c9">Project overview</span></p><p class="c2"><span class="c15">AIParrot is an intelligent conversational AI that uses machine leaving to generate responses to a given question. For a live demo, you can visit the website link().</span><span class="c27 c33">&nbsp;</span></p><p class="c1"><span class="c27 c33"></span></p><p class="c2"><span class="c9">Technology stack </span></p><p class="c2"><span class="c15">As AIParrot we use Python with Tensorflow and Keras as a deep learning framework of choice for machine learning tasks. For web interface and API, we use Python, Flask, and Bootstrap </span></p><p class="c1"><span class="c9"></span></p><p class="c2"><span class="c9">Get started</span></p><p class="c2"><span class="c14">To get started with AIParrot only pre-requirement is Python after installing python you can run &nbsp;&ldquo;pip install requirements.txt&ldquo; to install all dependencies AIParrot needs to run.</span></p><p class="c1"><span class="c9"></span></p><p class="c2"><span class="c9">General understanding of project </span></p><p class="c2"><span class="c16">Where to find code </span></p><p class="c2"><span class="c14">AIParrot is an open-source machine learning project and code is hosted on GitHub you can check out the code via the link(https://github.com/YigitGunduc/parrot)</span></p><p class="c1"><span class="c16"></span></p><p class="c2"><span class="c16">Dir structure </span></p><p class="c2"><span class="c14">AIParrot contains lots of nested files in this section I will explain some of the major files</span></p><p class="c2"><span class="c18 c15">AI</span><span class="c14">: AI folder contains two folders one named seq2seq and the one called &ldquo;seq2seqwithembedding&rdquo; seq2seq file contain code for bare-bones se2seq model and the &ldquo;seq2seqwithembedding&rdquo; folder contains a seq2seq model with embedding layers and GloVe vectors </span></p><p class="c1"><span class="c14"></span></p><p class="c2"><span class="c18 c15">Docs</span><span class="c14">: contain documentation of AIParrot</span></p><p class="c1"><span class="c14"></span></p><p class="c2"><span class="c15 c18">Platform</span><span class="c15">: platform folder contains the web-app and Twitter support folder. Actually, these folders are pretty self-explanatory web-app folder contains both the web app and the &nbsp;API and the twitter-support folder contain twitter API</span></p><p class="c1"><span class="c9"></span></p><p class="c2"><span class="c9">Seq2seq Models</span></p><p class="c1"><span class="c16"></span></p><p class="c2"><span class="c10">Seq2Seq model takes a sequence in this case sentences and outputs another sequence. The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence. In our case, we have two of them. The first one is bare-bones seq2seq and the other one uses embedding and GloVe vectors to increase the learning rate. For more information about GloVe vectors, you can check out Stanford&rsquo;s page.</span></p><p class="c2"><span class="c15">(link: https://nlp.stanford.edu/projects/glove/)</span></p><p class="c1"><span class="c19 c18 c21"></span></p><p class="c2"><span class="c18 c26">Generate response from a pre-trained model</span></p><p class="c2"><span class="c15">There are a couple of ways to generate a response from AIParrot I will explain all of them in the section below</span></p><p class="c1"><span class="c19 c18 c31"></span></p><p class="c2"><span class="c16">Web app </span></p><p class="c2"><span class="c14">Webapp is the easiest way to ask a question to the AIParrot</span></p><p class="c1"><span class="c14"></span></p><p class="c2"><span class="c16">API </span></p><p class="c2"><span class="c14">If you want to integrate AIParrot with your project API is just for you there is an easy to use API for example request you can check the &ldquo;platform/ExampleApiRequest.py&rdquo; file or the code below</span></p><p class="c1"><span class="c14"></span></p><p class="c2"><span class="c6">import</span><span class="c4">&nbsp;requests </span></p><p class="c1"><span class="c4"></span></p><p class="c2"><span class="c8">response </span><span class="c29">=</span><span class="c8">&nbsp;requests.</span><span class="c7">get</span><span class="c8">(</span><span class="c32">&quot;URL&quot;</span><span class="c4">)</span></p><p class="c2"><span class="c5">#raw response</span></p><p class="c2"><span class="c7">print</span><span class="c8">(response.</span><span class="c7">json</span><span class="c4">())</span></p><p class="c2"><span class="c5">#cleaned up response</span></p><p class="c25"><span class="c7">print</span><span class="c8">(response.</span><span class="c7">json</span><span class="c8">()[</span><span class="c32">&quot;response&quot;</span><span class="c8">])</span></p><p class="c1"><span class="c3"></span></p><p class="c1"><span class="c3"></span></p><p class="c1"><span class="c3"></span></p><p class="c1"><span class="c3"></span></p><p class="c1"><span class="c3"></span></p><p class="c2"><span class="c18 c34">Train your own model</span><span class="c9">&nbsp;</span></p><p class="c2"><span class="c14">To train your own model navigate to the desired folder(&ldquo;seq2seqwithembedding&rdquo; or seq2seq) there is no right model but I highly encourage you to train seq2seqwithembedding if you have resources. After you choose your model you can run the train.py file and it will generate model files for you. It takes the data batch by batch and all the batches contain 10000 lines our dataset has 320000 lines so it will generate around &nbsp;30 &nbsp;&ldquo;.h5&rdquo; extension files after training has done you better to go through end eval at leas each fifth tenth, fifteenth &hellip; the last model to find which batch fits your needs best &nbsp;</span></p><p class="c1"><span class="c9"></span></p><p class="c2"><span class="c9">Eval your model </span></p><p class="c2"><span class="c14">Firstly give the exact path to your own model to the eval.py after that you can run eval.py to generate responses from it. Eval.py will pick questions from the dataset if you want to give it specific questions and see how it behaves. You can run the web app in your localhost and give it your own model to see how it behaves.</span></p><p class="c1"><span class="c9"></span></p><p class="c2"><span class="c9">Contributions </span></p><p class="c23 c24"><span class="c11">Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.</span></p><ol class="c0 lst-kix_c0yxfgf3c3ml-0 start" start="1"><li class="c24 c23 c28"><span class="c11">Fork the Project</span></li><li class="c12"><span class="c17 c15">Create your Feature Branch (</span><span class="c8">git checkout -b feature/AmazingFeature</span><span class="c11">)</span></li><li class="c12"><span class="c15 c17">Commit your changes (</span><span class="c8">git commit -m &#39;Add some AmazingFeature&#39;</span><span class="c11">)</span></li><li class="c12"><span class="c17 c15">Push to the Branch (</span><span class="c8">git push origin feature/AmazingFeature</span><span class="c11">)</span></li><li class="c12"><span class="c11">Open a Pull Request</span></li></ol><p class="c1"><span class="c9"></span></p><p class="c1"><span class="c13"></span></p><p class="c1"><span class="c13"></span></p><p class="c1"><span class="c13"></span></p><p class="c1"><span class="c13"></span></p><p class="c2"><span class="c17 c18 c26">License</span></p><p class="c2 c23"><span class="c17 c35">This project is licensed under the MIT License (see the </span><span class="c17 c30">LICENSE</span><span class="c17 c27">&nbsp;file for details).</span></p></div></body></html>